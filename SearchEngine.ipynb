{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *STEP1:* 将原来6G的xml文件切分成平均1M的小文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49125\n"
     ]
    }
   ],
   "source": [
    "RUN = False\n",
    "if(RUN):  \n",
    "    fin = open('zhwiki-20171020-pages-articles-multistream.xml',encoding='utf8')\n",
    "    for i in range(10000000):      \n",
    "        readin = fin.readlines(100*1000)\n",
    "        if(not readin):\n",
    "            break\n",
    "        fout = open('parts/part_'+str(i),'w',encoding = 'utf8')\n",
    "        fout.writelines(readin)\n",
    "        # fout.writelines(re.sub(\"[\\[\\]\\'\\\"\\@#$%^&*()<>：{}|/_.+-—，,。!！ ？、~@#￥%……&*（）]+\", \"\",s))\n",
    "        fout.close()\n",
    "    fin.close()\n",
    "    partsNum = i\n",
    "    print(partsNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTION** 判断一个unicode是否为汉字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_ch(uchar):\n",
    "        \"\"\"判断一个unicode是否是汉字\"\"\"\n",
    "        if uchar >= u'\\u4e00' and uchar<=u'\\u9fa5':\n",
    "                return True\n",
    "        else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *STEP2:* 导入GBK编码表，构造一个dic，将汉字映射到整数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词典大小： 20902\n"
     ]
    }
   ],
   "source": [
    "with open('GBK',encoding='utf8') as fin:\n",
    "    chList = []\n",
    "    for line in fin.readlines():\n",
    "        for word in line:\n",
    "            if(is_ch(word)):\n",
    "                chList.append(word)\n",
    "\n",
    "                \n",
    "chNum = len(chList)\n",
    "print('词典大小：',chNum)\n",
    "ch2int = {}\n",
    "idx = 0\n",
    "with open('ch2int','w',encoding='utf8') as fout:  \n",
    "    for w in chList:\n",
    "        ch2int[w] = idx\n",
    "        fout.write(w+'\\t'+str(idx)+'\\n')\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASS** 定义类BitSet 用于集合运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BitSet:\n",
    "    def __init__(self, elementNum):\n",
    "        self.bytesNum = round(elementNum/8)\n",
    "        self.set = bytearray(self.bytesNum)\n",
    "        \n",
    "    def insert(self, index):\n",
    "        if(index >= 0 and index>>3 < self.bytesNum):\n",
    "            self.set[index >> 3] = self.set[index >> 3] | (1 << int(index & 7)) \n",
    "            return True;\n",
    "        return False;\n",
    "    \n",
    "    def isElement(self, index):\n",
    "        if(index >= 0 and index>>3 < self.bytesNum and (self.set[index >> 3] & (1<<(index & 7)))):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def AND(self, bs):\n",
    "        a = BitSet(self.bytesNum*8)\n",
    "        for i in range(self.bytesNum):\n",
    "            a.set[i] = self.set[i] & bs.set[i]\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *STEP3:* 给每一个汉字创建倒排索引，对应包含该汉字的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个字的倒排索引表的字节数： 6141\n"
     ]
    }
   ],
   "source": [
    "partsNum = 49125\n",
    "bytesNum = round(partsNum/8)\n",
    "\n",
    "invertedIndex = [BitSet(partsNum) for i in range(chNum)]\n",
    "print('每个字的倒排索引表的字节数：',invertedIndex[0].bytesNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTION** 显示进度条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,time\n",
    "\n",
    "def processBar(index, totalNum):\n",
    "    bar = '#'*int((index/totalNum)*50)\n",
    "    sys.stdout.write(str(int((index/totalNum)*100))+'%  ||'+bar+'->'+\"\\r\")\n",
    "    #sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历所有文档的所有字符，建立倒排索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%  ||#################################################->\r"
     ]
    }
   ],
   "source": [
    "\n",
    "#for partIdx in range(partsNum):\n",
    "for partIdx in range(100):   \n",
    "    processBar(partIdx, partsNum)\n",
    "    \n",
    "    with open('parts/part_'+str(partIdx),encoding='utf8') as f:\n",
    "        for word in f.read():\n",
    "            try:\n",
    "                if(is_ch(word)):\n",
    "                    invertedIndex[ch2int[word]].insert(partIdx)\n",
    "            except KeyError as err:\n",
    "                print('KEY ERROR'+str(err))\n",
    "\n",
    "for chIdx in range(chNum):    \n",
    "    processBar(chIdx, chNum)\n",
    "    with open('iidx/ch_'+str(chIdx)+'.iidx','w',encoding='utf8') as f:\n",
    "            for j in invertedIndex[chIdx].set:\n",
    "                f.write(str(j)+' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：读取倒排索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'\\x07\\x08\\x06\\x00\\x002\\n\\x0c\\x00\\x18\\x08\\x14\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n"
     ]
    }
   ],
   "source": [
    "def readIidx(file):\n",
    "    with open(file,encoding='utf8') as f:\n",
    "        s = f.read()[:-1].split(' ')\n",
    "    bSet = BitSet(len(s)*8)\n",
    "    for i in range(bSet.bytesNum):\n",
    "        bSet.set[i] = int(s[i])\n",
    "    return bSet\n",
    "\n",
    "f = 'iidx/ch_0.iidx'\n",
    "b = readIidx(f)\n",
    "print(b.set[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *STEP4:* 建立每个文档的 tf 表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf \n",
    "RUN_tf = False\n",
    "\n",
    "if(RUN_tf):\n",
    "    for partIdx in range(partsNum):\n",
    "\n",
    "        tf = [0.0 for i in range(chNum)]\n",
    "        total = 0\n",
    "\n",
    "        with open('parts/part_'+str(partIdx),encoding='utf8') as f:\n",
    "            for word in f.read():\n",
    "                if(is_ch(word)):\n",
    "                    tf[ch2int[word]] += 1\n",
    "                    total += 1\n",
    "\n",
    "        total = max(total, 1)\n",
    "        for i in range(chNum):\n",
    "            tf[i] /= total\n",
    "\n",
    "        with open('parts/tf/part_'+str(partIdx)+'.tf','w',encoding='utf8') as fout:\n",
    "            for i in tf:\n",
    "                fout.write(str(i)+' ')\n",
    "                \n",
    "        processBar(partIdx, partsNum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### *STEP5:* 计算每个单词的 idf 值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%  ||#################################################->\r"
     ]
    }
   ],
   "source": [
    "# idf(ch) = log(total DocumentNum / Num of documents containing ch)\n",
    "import math\n",
    "\n",
    "idf = [0.0 for i in range(chNum)]\n",
    "\n",
    "for chIdx in range(chNum):\n",
    "    processBar(chIdx, chNum)\n",
    "    num = 0\n",
    "    iidxFile = 'iidx/ch_'+str(chIdx)+'.iidx'\n",
    "    bs = readIidx(iidxFile)\n",
    "    for i in range(partsNum):\n",
    "        if(bs.isElement(i)):\n",
    "            num += 1\n",
    "    idf[chIdx] = math.log(partsNum/(num+1)) # divide by zero\n",
    "\n",
    "with open('iidx/idf','w',encoding='utf8') as fout:\n",
    "    for i in idf:\n",
    "        fout.write(str(i)+' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *STEP6:* 搜索到包含关键词的文档集, 将搜索到的文档集根据 tf-idf 值排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "（文档号，TFIDF值）\n",
      "(95, 0.7542362578147894)\n",
      "(32, 0.6203344862114203)\n",
      "(37, 0.5982827394017244)\n",
      "(39, 0.5551600755994012)\n",
      "(30, 0.5514309729312883)\n",
      "(44, 0.4623889179372404)\n",
      "(33, 0.41754225957672414)\n",
      "(94, 0.40984699051540074)\n",
      "(78, 0.3926799381317715)\n",
      "(64, 0.29895649752851083)\n"
     ]
    }
   ],
   "source": [
    "def mask(bytes):\n",
    "    r = BitSet(bytes*8)\n",
    "    for i in range(bytes):\n",
    "        r.set[i] = 255\n",
    "    return r\n",
    "\n",
    "bsMask = mask(bytesNum) # 掩码\n",
    "\n",
    "def getIdf(partIdx):\n",
    "    file = 'iidx/idf'\n",
    "    with open(file, encoding='utf8') as f:\n",
    "        s = f.read().split()\n",
    "    return float(s[partIdx])\n",
    "\n",
    "def tfidf(partIdx, keyList):\n",
    "    file = 'parts/tf/part_'+str(partIdx)+'.tf'\n",
    "    tf = 0\n",
    "    with open(file,encoding='utf8') as f:\n",
    "        s = f.read().split()\n",
    "        for i in keyList:\n",
    "            tf += float(s[i])\n",
    "    idf = getIdf(partIdx)\n",
    "    return tf*idf\n",
    "\n",
    "def search(query):\n",
    "    keyList = []\n",
    "    targets = bsMask\n",
    "    for word in query:\n",
    "        if(is_ch(word)):\n",
    "            keyList.append(ch2int[word])\n",
    "            targets = targets.AND(readIidx('iidx/ch_'+str(ch2int[word])+'.iidx'))\n",
    "            \n",
    "    result = []\n",
    "    for i in range(partsNum):\n",
    "        if(targets.isElement(i)):\n",
    "            result.append(i)\n",
    "    \n",
    "    # rearrange\n",
    "    tuples = []\n",
    "    for doc in result:\n",
    "        tuples.append((doc, tfidf(doc,keyList)))\n",
    "    \n",
    "    result = sorted(tuples, key = lambda x:x[1], reverse=True)\n",
    "        \n",
    "    return result\n",
    "\n",
    "r = search('蒋介石毛泽东周恩来邓小平中国台湾国名党共产党')\n",
    "print(\"（文档号，TFIDF值）\")\n",
    "for i in r[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假如每次只取出前十名，每篇文档大小100kb，总共只占用1M内存，完全可以将所有文字体取出来分析，找到最佳匹配的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
